# Описание скриптов подготовки данных

## Структура папок
python/
└── data_processing/
├── analyze_dataset.py # Основная обработка данных
└── check_seasonality.py # Анализ сезонности и качества



## 1. analyze_dataset.py
**Назначение**: Первичная обработка и преобразование сырых данных

**Что делает**:
- Загружает CSV с трафиком Wikipedia страниц
- Извлекает данные по конкретной странице ("Back to the Future") 
- Преобразует широкий формат данных в временной ряд
- Создает столбец с датами (2018-01-01 - 2019-12-31)
- Сохраняет очищенные данные в `data/processed/time_series.csv`
- Строит обзорный график трафика

**Вход**: `data/processed/selected_page.csv` (одна строка из исходного датасета)
**Выход**: 
- `data/processed/time_series.csv` (очищенные данные)
- `results/graphs/traffic_overview.png` (график трафика)

## 2. check_seasonality.py  
**Назначение**: Анализ качества данных и проверка сезонности

**Что делает**:
- Проверяет данные на пропуски и аномалии
- Выполняет сезонную декомпозицию (тренд + сезонность + остатки)
- Визуализирует компоненты временного ряда
- Подтверждает наличие недельной сезонности для Holt-Winters

**Вход**: `data/processed/time_series.csv`
**Выход**: `results/graphs/seasonal_decomposition.png`

## Логика разделения
Оба скрипта работают с данными, но решают разные задачи:
- `analyze_dataset.py` - преобразование формата данных
- `check_seasonality.py` - аналитика и валидация данных

## Результат подготовки
Данные готовы для реализации алгоритма экспоненциального сглаживания на C++.